#!/usr/bin/env python3
"""
FACE RECOGNITION SYSTEM - INSIGHTFACE + DEEPFACE + YOLOv11-POSE + ATTENDANCE + REAL-TIME BACKEND
G·ª≠i d·ªØ li·ªáu real-time cho backend m·ªói gi√¢y - ƒê√É S·ª¨A L·ªñI UnboundLocalError
"""

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.preprocessing import Normalizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pickle
import time
import subprocess
import sys
from datetime import datetime
import requests
import json

# ==================== C√ÄI ƒê·∫∂T DEPENDENCIES ====================
def install_dependencies():
    """T·ª± ƒë·ªông c√†i ƒë·∫∑t dependencies n·∫øu ch∆∞a c√≥"""
    packages = [
        "torch",
        "torchvision", 
        "opencv-python", 
        "matplotlib",
        "scikit-learn",
        "pillow",
        "numpy",
        "insightface",
        "onnxruntime",
        "deepface",
        "pandas",
        "tf-keras",
        "tensorflow",
        "ultralytics",
        "requests"
    ]
    
    print("üîß Ki·ªÉm tra v√† c√†i ƒë·∫∑t dependencies...")
    
    for package in packages:
        try:
            if package == "torch":
                __import__("torch")
            elif package == "torchvision":
                __import__("torchvision")
            elif package == "insightface":
                __import__("insightface")
            elif package == "deepface":
                __import__("deepface")
            elif package == "ultralytics":
                __import__("ultralytics")
            elif package == "requests":
                __import__("requests")
            else:
                __import__(package.replace('-', '_'))
            print(f"‚úÖ {package} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        except ImportError:
            print(f"üì• ƒêang c√†i ƒë·∫∑t {package}...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", package])
            print(f"‚úÖ ƒê√£ c√†i ƒë·∫∑t {package}")

# ==================== BACKEND DATA SENDER ====================
class BackendDataSender:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.is_connected = False
        self.last_sent_time = 0
        self.send_interval = 1.0  # G·ª≠i m·ªói 1 gi√¢y
        self.test_connection()
    
    def test_connection(self):
        """Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn backend"""
        try:
            response = requests.get(f"{self.base_url}/api/health", timeout=3)
            if response.status_code == 200:
                self.is_connected = True
                print("‚úÖ ƒê√£ k·∫øt n·ªëi ƒë·∫øn backend th√†nh c√¥ng!")
            else:
                print(f"‚ö†Ô∏è Backend tr·∫£ v·ªÅ m√£ l·ªói: {response.status_code}")
                self.is_connected = False
        except Exception as e:
            print(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn backend: {str(e)}")
            self.is_connected = False
    
    def can_send_realtime(self):
        """Ki·ªÉm tra xem c√≥ th·ªÉ g·ª≠i real-time data kh√¥ng"""
        current_time = time.time()
        if current_time - self.last_sent_time >= self.send_interval:
            self.last_sent_time = current_time
            return True
        return False
    
    def send_realtime_data(self, student_data_list):
        """G·ª≠i d·ªØ li·ªáu real-time cho t·∫•t c·∫£ h·ªçc sinh ƒë∆∞·ª£c ph√°t hi·ªán"""
        if not self.is_connected or not self.can_send_realtime():
            return False
        
        try:
            # T√≠nh to√°n th·ªëng k√™
            present_count = len([s for s in student_data_list if s.get('status') == 'present'])
            total_count = len(student_data_list)
            
            # T√≠nh emotion distribution
            emotion_count = {}
            engagement_scores = []
            
            for student in student_data_list:
                emotion = student.get('emotion', 'neutral')
                emotion_count[emotion] = emotion_count.get(emotion, 0) + 1
                engagement_scores.append(student.get('engagement', 0))
            
            avg_engagement = np.mean(engagement_scores) * 100 if engagement_scores else 75.0
            dominant_emotion = max(emotion_count.items(), key=lambda x: x[1])[0] if emotion_count else 'neutral'
            
            data = {
                "type": "live_update",
                "timestamp": datetime.now().isoformat(),
                "students": student_data_list,
                "stats": {
                    "total_students": total_count,
                    "present_count": present_count,
                    "absent_count": max(5 - present_count, 0),  # Gi·∫£ ƒë·ªãnh l·ªõp c√≥ 5 h·ªçc sinh
                    "attendance_rate": round((present_count / max(total_count, 1)) * 100, 1),
                    "avg_engagement": round(avg_engagement, 1),
                    "current_emotion": dominant_emotion
                }
            }
            
            # G·ª≠i qua endpoint ch√≠nh c·ªßa backend
            response = requests.post(
                f"{self.base_url}/api/realtime/update",
                json=data,
                timeout=2
            )
            
            if response.status_code == 200:
                print(f"üì§ Real-time: {len(student_data_list)} students, {avg_engagement:.1f}% engagement")
                return True
            else:
                # Th·ª≠ g·ª≠i qua WebSocket endpoint
                try:
                    ws_response = requests.post(
                        f"{self.base_url}/api/websocket/broadcast",
                        json=data,
                        timeout=2
                    )
                    return ws_response.status_code == 200
                except:
                    return False
                
        except Exception as e:
            # print(f"‚ùå L·ªói g·ª≠i real-time data: {str(e)}")
            return False

    def send_face_detection(self, student_id, student_name, emotion, confidence, bbox):
        """G·ª≠i d·ªØ li·ªáu nh·∫≠n di·ªán khu√¥n m·∫∑t ƒë·∫øn backend"""
        if not self.is_connected:
            return False
        
        try:
            data = {
                "student_id": student_id,
                "student_name": student_name,
                "emotion": emotion,
                "confidence": confidence,
                "bbox": bbox
            }
            
            response = requests.post(
                f"{self.base_url}/api/detections/",
                json=data,
                timeout=3
            )
            
            return response.status_code == 200
                
        except Exception as e:
            print(f"‚ùå L·ªói g·ª≠i face detection: {str(e)}")
            return False
    
    def send_behavior_data(self, student_id, student_name, behavior_type, score, details=None):
        """G·ª≠i d·ªØ li·ªáu h√†nh vi ƒë·∫øn backend"""
        if not self.is_connected:
            return False
        
        try:
            data = {
                "student_id": student_id,
                "student_name": student_name,
                "behavior_type": behavior_type,
                "score": score,
                "details": details or "{}"
            }
            
            response = requests.post(
                f"{self.base_url}/api/behavior/",
                json=data,
                timeout=3
            )
            
            return response.status_code == 200
                
        except Exception as e:
            print(f"‚ùå L·ªói g·ª≠i behavior data: {str(e)}")
            return False
    
    def mark_attendance(self, student_id, student_name, status="present"):
        """ƒêi·ªÉm danh h·ªçc sinh tr√™n backend"""
        if not self.is_connected:
            return False
        
        try:
            now = datetime.now()
            data = {
                "student_id": student_id,
                "student_name": student_name,
                "date": now.strftime("%Y-%m-%d"),
                "status": status,
                "check_in_time": now.isoformat()
            }
            
            response = requests.post(
                f"{self.base_url}/api/attendance/mark",
                json=data,
                timeout=3
            )
            
            if response.status_code == 200:
                print(f"‚úÖ ƒê√£ ƒëi·ªÉm danh tr√™n backend: {student_name}")
                return True
            else:
                print(f"‚ö†Ô∏è L·ªói ƒëi·ªÉm danh tr√™n backend: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå L·ªói ƒëi·ªÉm danh tr√™n backend: {str(e)}")
            return False

# ==================== BEHAVIOR DETECTION WITH YOLOv11-POSE ====================
class BehaviorDetector:
    def __init__(self):
        self.pose_model = None
        self.initialize_pose_detector()
    
    def initialize_pose_detector(self):
        """Kh·ªüi t·∫°o YOLOv11 pose detector"""
        try:
            from ultralytics import YOLO
            
            # Load YOLOv11 pose model
            self.pose_model = YOLO('yolo11n-pose.pt')  # S·∫Ω t·ª± ƒë·ªông download
            print("‚úÖ YOLOv11 Pose detector ƒë√£ s·∫µn s√†ng")
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o YOLOv11 Pose: {str(e)}")
            return False
    
    def detect_behavior(self, image):
        """Nh·∫≠n di·ªán h√†nh vi t·ª´ pose estimation"""
        try:
            # Run pose detection
            results = self.pose_model(image, verbose=False)
            
            behaviors = []
            
            for result in results:
                if hasattr(result, 'keypoints') and result.keypoints is not None and len(result.keypoints) > 0:
                    for person_idx, keypoints in enumerate(result.keypoints.data):
                        # L·∫•y keypoints (17 points, m·ªói point c√≥ [x, y, confidence])
                        kpts = keypoints.cpu().numpy()
                        
                        # Ph√¢n t√≠ch h√†nh vi d·ª±a tr√™n keypoints
                        behavior = self._analyze_pose_behavior(kpts)
                        
                        # L·∫•y bounding box n·∫øu c√≥
                        bbox = None
                        if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > person_idx:
                            bbox = result.boxes[person_idx].xyxy[0].cpu().numpy()
                        
                        behaviors.append({
                            'behavior': behavior,
                            'keypoints': kpts,
                            'bbox': bbox,
                            'person_idx': person_idx
                        })
            
            return behaviors
            
        except Exception as e:
            print(f"‚ùå L·ªói nh·∫≠n di·ªán h√†nh vi: {str(e)}")
            return []
    
    def _analyze_pose_behavior(self, keypoints):
        """Ph√¢n t√≠ch h√†nh vi d·ª±a tr√™n keypoints pose"""
        try:
            # Ch·ªâ s·ªë keypoints theo COCO format
            NOSE = 0
            LEFT_EYE = 1
            RIGHT_EYE = 2
            LEFT_EAR = 3
            RIGHT_EAR = 4
            LEFT_SHOULDER = 5
            RIGHT_SHOULDER = 6
            LEFT_ELBOW = 7
            RIGHT_ELBOW = 8
            LEFT_WRIST = 9
            RIGHT_WRIST = 10
            LEFT_HIP = 11
            RIGHT_HIP = 12
            LEFT_KNEE = 13
            RIGHT_KNEE = 14
            LEFT_ANKLE = 15
            RIGHT_ANKLE = 16
            
            # L·∫•y t·ªça ƒë·ªô keypoints
            def get_point(idx):
                if keypoints[idx][2] > 0.3:  # Confidence threshold
                    return keypoints[idx][:2]
                return None
            
            # L·∫•y c√°c ƒëi·ªÉm quan tr·ªçng
            left_shoulder = get_point(LEFT_SHOULDER)
            right_shoulder = get_point(RIGHT_SHOULDER)
            left_elbow = get_point(LEFT_ELBOW)
            right_elbow = get_point(RIGHT_ELBOW)
            left_wrist = get_point(LEFT_WRIST)
            right_wrist = get_point(RIGHT_WRIST)
            left_hip = get_point(LEFT_HIP)
            right_hip = get_point(RIGHT_HIP)
            left_knee = get_point(LEFT_KNEE)
            right_knee = get_point(RIGHT_KNEE)
            
            # Ph√¢n t√≠ch c√°c h√†nh vi
            behaviors = []
            
            # 1. Ki·ªÉm tra gi∆° tay
            if left_wrist is not None and left_shoulder is not None:
                if left_wrist[1] < left_shoulder[1]:
                    behaviors.append("raising_hand")
            if right_wrist is not None and right_shoulder is not None:
                if right_wrist[1] < right_shoulder[1]:
                    behaviors.append("raising_hand")
            
            # 2. Ki·ªÉm tra ƒë·ª©ng l√™n/ng·ªìi xu·ªëng
            if (left_hip is not None and left_knee is not None and 
                right_hip is not None and right_knee is not None):
                hip_height = (left_hip[1] + right_hip[1]) / 2
                knee_height = (left_knee[1] + right_knee[1]) / 2
                if abs(hip_height - knee_height) < 50:  # ƒê·ª©ng
                    behaviors.append("standing")
                else:  # Ng·ªìi
                    behaviors.append("sitting")
            
            # 3. Ki·ªÉm tra v·ªó tay
            if left_wrist is not None and right_wrist is not None:
                distance = np.sqrt(np.sum((left_wrist - right_wrist) ** 2))
                if distance < 50:
                    behaviors.append("clapping")
            
            # 4. Ki·ªÉm tra ƒëi b·ªô/ch·∫°y
            if (left_hip is not None and right_hip is not None and 
                left_knee is not None and right_knee is not None):
                hip_distance = abs(left_hip[0] - right_hip[0])
                if hip_distance > 30:
                    behaviors.append("walking")
            
            # 5. M·∫∑c ƒë·ªãnh
            if not behaviors:
                behaviors.append("normal")
            
            return ", ".join(behaviors)
            
        except Exception as e:
            print(f"‚ùå L·ªói ph√¢n t√≠ch h√†nh vi: {str(e)}")
            return "unknown"

# ==================== ATTENDANCE SYSTEM ====================
class AttendanceSystem:
    def __init__(self, csv_file="attendance.csv"):
        self.csv_file = csv_file
        self.backend_sender = BackendDataSender()
        self.initialize_attendance_file()
    
    def initialize_attendance_file(self):
        """Kh·ªüi t·∫°o file ƒëi·ªÉm danh"""
        try:
            if not os.path.exists(self.csv_file):
                df = pd.DataFrame(columns=[
                    'Name', 'Date', 'Time', 'Emotion', 'Behavior', 'Confidence'
                ])
                df.to_csv(self.csv_file, index=False)
                print(f"‚úÖ ƒê√£ t·∫°o file ƒëi·ªÉm danh: {self.csv_file}")
            else:
                df = pd.read_csv(self.csv_file)
                print(f"‚úÖ File ƒëi·ªÉm danh ƒë√£ t·ªìn t·∫°i: {len(df)} records")
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o file ƒëi·ªÉm danh: {str(e)}")
            df = pd.DataFrame(columns=[
                'Name', 'Date', 'Time', 'Emotion', 'Behavior', 'Confidence'
            ])
            df.to_csv(self.csv_file, index=False)
    
    def mark_attendance(self, name, emotion, behavior, confidence, bbox=None):
        """ƒêi·ªÉm danh v√†o file CSV v√† g·ª≠i l√™n backend"""
        try:
            now = datetime.now()
            date_str = now.strftime("%Y-%m-%d")
            time_str = now.strftime("%H:%M:%S")
            
            # T·∫°o student_id t·ª´ t√™n (cho demo)
            student_id = f"SV{hash(name) % 10000:04d}"
            
            # G·ª≠i d·ªØ li·ªáu l√™n backend
            if self.backend_sender.is_connected:
                # G·ª≠i face detection data
                self.backend_sender.send_face_detection(
                    student_id=student_id,
                    student_name=name,
                    emotion=emotion,
                    confidence=confidence,
                    bbox=bbox or {"x1": 0, "y1": 0, "x2": 100, "y2": 100}
                )
                
                # G·ª≠i behavior data
                engagement_score = confidence * 100
                self.backend_sender.send_behavior_data(
                    student_id=student_id,
                    student_name=name,
                    behavior_type="engagement",
                    score=engagement_score,
                    details=json.dumps({"behavior": behavior, "emotion": emotion})
                )
                
                # ƒêi·ªÉm danh
                self.backend_sender.mark_attendance(student_id, name, "present")
            
            # L∆∞u v√†o file local
            try:
                df = pd.read_csv(self.csv_file)
            except:
                df = pd.DataFrame(columns=[
                    'Name', 'Date', 'Time', 'Emotion', 'Behavior', 'Confidence'
                ])
            
            # Ki·ªÉm tra ƒëi·ªÉm danh trong v√≤ng 2 ph√∫t
            two_minutes_ago = (datetime.now() - pd.Timedelta(minutes=2)).strftime("%H:%M:%S")
            recent_entries = df[
                (df['Name'] == name) & 
                (df['Date'] == date_str) & 
                (df['Time'] > two_minutes_ago)
            ]
            
            if len(recent_entries) == 0:
                new_entry = {
                    'Name': name,
                    'Date': date_str,
                    'Time': time_str,
                    'Emotion': emotion,
                    'Behavior': behavior,
                    'Confidence': f"{confidence:.4f}"
                }
                
                df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)
                df.to_csv(self.csv_file, index=False)
                print(f"‚úÖ ƒê√£ ƒëi·ªÉm danh: {name} | üòä {emotion} | üéØ {behavior}")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"‚ùå L·ªói ƒëi·ªÉm danh: {str(e)}")
            return False
    
    def view_attendance(self):
        """Xem l·ªãch s·ª≠ ƒëi·ªÉm danh"""
        try:
            if not os.path.exists(self.csv_file):
                print("üì≠ Ch∆∞a c√≥ file ƒëi·ªÉm danh")
                return
                
            df = pd.read_csv(self.csv_file)
            if len(df) > 0:
                print("\nüìä L·ªäCH S·ª¨ ƒêI·ªÇM DANH:")
                print("=" * 80)
                for _, row in df.iterrows():
                    print(f"üë§ {row['Name']} | üìÖ {row['Date']} | üïí {row['Time']} | üòä {row['Emotion']} | üéØ {row['Behavior']}")
                print("=" * 80)
                print(f"üìà T·ªïng s·ªë l∆∞·ª£t ƒëi·ªÉm danh: {len(df)}")
            else:
                print("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu ƒëi·ªÉm danh")
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file ƒëi·ªÉm danh: {str(e)}")

# ==================== EMOTION DETECTION ====================
class EmotionDetector:
    def __init__(self):
        self.emotion_model = None
    
    def detect_emotion(self, face_image):
        """Nh·∫≠n di·ªán c·∫£m x√∫c t·ª´ khu√¥n m·∫∑t"""
        try:
            from deepface import DeepFace
            
            # Chuy·ªÉn ƒë·ªïi ·∫£nh sang RGB
            face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
            
            # Ph√¢n t√≠ch c·∫£m x√∫c
            analysis = DeepFace.analyze(
                face_rgb, 
                actions=['emotion'],
                enforce_detection=False,
                silent=True
            )
            
            if isinstance(analysis, list):
                analysis = analysis[0]
            
            emotion = analysis['dominant_emotion']
            emotion_confidence = analysis['emotion'][emotion]
            
            return emotion, emotion_confidence
            
        except Exception as e:
            print(f"‚ùå L·ªói nh·∫≠n di·ªán c·∫£m x√∫c: {str(e)}")
            return "unknown", 0.0

# ==================== FACE RECOGNITION SYSTEM ====================
class CompleteRecognitionSystem:
    def __init__(self, model_name='buffalo_l'):
        self.model_name = model_name
        self.face_analyzer = None
        self.l2_normalizer = Normalizer('l2')
        self.emotion_detector = EmotionDetector()
        self.behavior_detector = BehaviorDetector()
        self.attendance_system = AttendanceSystem()
        self.backend_sender = BackendDataSender()
        
    def initialize_system(self):
        """Kh·ªüi t·∫°o to√†n b·ªô h·ªá th·ªëng"""
        print("üöÄ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng ho√†n ch·ªânh...")
        
        # Kh·ªüi t·∫°o InsightFace
        try:
            import insightface
            from insightface.app import FaceAnalysis
            
            self.face_analyzer = FaceAnalysis(
                name=self.model_name,
                providers=['CPUExecutionProvider']
            )
            self.face_analyzer.prepare(ctx_id=0, det_size=(640, 640))
            print("‚úÖ InsightFace ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
            
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o InsightFace: {str(e)}")
            return False
        
        # Kh·ªüi t·∫°o Behavior Detector
        if not self.behavior_detector.initialize_pose_detector():
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ kh·ªüi t·∫°o Behavior Detector")
        
        print("‚úÖ H·ªá th·ªëng ho√†n ch·ªânh ƒë√£ s·∫µn s√†ng!")
        return True

    def detect_faces(self, image):
        """Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi InsightFace"""
        try:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            faces = self.face_analyzer.get(image_rgb)
            
            face_results = []
            for face in faces:
                bbox = face.bbox.astype(int)
                x1, y1, x2, y2 = bbox
                w = x2 - x1
                h = y2 - y1
                
                face_roi = image[y1:y2, x1:x2]
                if face_roi.size == 0:
                    continue
                
                embedding = face.normed_embedding
                
                # Nh·∫≠n di·ªán c·∫£m x√∫c
                emotion, emotion_conf = self.emotion_detector.detect_emotion(face_roi)
                
                face_results.append({
                    'face_image': face_roi,
                    'bbox': (x1, y1, w, h),
                    'embedding': embedding,
                    'det_score': face.det_score,
                    'landmarks': face.kps if hasattr(face, 'kps') else None,
                    'emotion': emotion,
                    'emotion_confidence': emotion_conf
                })
            
            return face_results
            
        except Exception as e:
            print(f"‚ùå L·ªói detect faces: {str(e)}")
            return []

    def extract_features(self, face_data):
        """Tr√≠ch xu·∫•t features t·ª´ khu√¥n m·∫∑t"""
        try:
            embedding = face_data['embedding']
            embedding = embedding.reshape(1, -1)
            features_normalized = self.l2_normalizer.transform(embedding)
            return features_normalized[0]
        except Exception as e:
            print(f"‚ùå L·ªói extract features: {str(e)}")
            return None

    def train_face_recognition(self, database_path="database"):
        """Train h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t"""
        if not os.path.exists(database_path):
            print(f"‚ùå Th∆∞ m·ª•c database kh√¥ng t·ªìn t·∫°i: {database_path}")
            return False
        
        database = {}
        features_list = []
        labels_list = []
        
        print("üìÅ ƒêang x·ª≠ l√Ω database...")
        
        persons = [p for p in os.listdir(database_path) if os.path.isdir(os.path.join(database_path, p))]
        if len(persons) < 1:
            print("‚ùå Kh√¥ng c√≥ ng∆∞·ªùi n√†o trong database!")
            return False
        
        for person_name in persons:
            person_path = os.path.join(database_path, person_name)
            print(f"üë§ ƒêang x·ª≠ l√Ω: {person_name}")
            person_features = []
            
            image_files = [f for f in os.listdir(person_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            for image_file in image_files:
                image_path = os.path.join(person_path, image_file)
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                face_results = self.detect_faces(image)
                for face_data in face_results:
                    features = self.extract_features(face_data)
                    if features is not None:
                        person_features.append(features)
                        features_list.append(features)
                        labels_list.append(person_name)
            
            if person_features:
                database[person_name] = person_features
                print(f"  ‚ûï {person_name}: {len(person_features)} khu√¥n m·∫∑t")
        
        if len(features_list) == 0:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ train!")
            return False
        
        print(f"\nüìä Th·ªëng k√™ database:")
        print(f"üë• S·ªë ng∆∞·ªùi: {len(database)}")
        print(f"üñºÔ∏è T·ªïng khu√¥n m·∫∑t: {len(features_list)}")
        
        # Train SVM model
        print("\nüéØ ƒêang train SVM model...")
        self.svm_model = SVC(kernel='linear', probability=True, random_state=42)
        self.svm_model.fit(features_list, labels_list)
        
        accuracy = accuracy_score(labels_list, self.svm_model.predict(features_list))
        print(f"‚úÖ Training ho√†n t·∫•t! Accuracy: {accuracy:.4f}")
        
        # L∆∞u model
        with open("face_recognition_model.pkl", 'wb') as f:
            pickle.dump(self.svm_model, f)
        
        with open("face_database.pkl", 'wb') as f:
            pickle.dump({
                'database': database,
                'features': features_list,
                'labels': labels_list
            }, f)
        
        print("üíæ ƒê√£ l∆∞u model v√† database")
        return True

    def load_trained_model(self):
        """Load model ƒë√£ train"""
        try:
            with open("face_recognition_model.pkl", 'rb') as f:
                self.svm_model = pickle.load(f)
            
            with open("face_database.pkl", 'rb') as f:
                db_info = pickle.load(f)
            
            print(f"‚úÖ ƒê√£ load trained model - {len(self.svm_model.classes_)} classes")
            return True
            
        except FileNotFoundError:
            print("‚ùå Kh√¥ng t√¨m th·∫•y file model. Vui l√≤ng train model tr∆∞·ªõc.")
            return False

    def recognize_face(self, face_data, threshold=0.6):
        """Nh·∫≠n di·ªán khu√¥n m·∫∑t"""
        if not hasattr(self, 'svm_model') or self.svm_model is None:
            return "Unknown", 0.0
        
        features = self.extract_features(face_data)
        if features is None:
            return "Unknown", 0.0
        
        try:
            probabilities = self.svm_model.predict_proba([features])[0]
            max_prob = np.max(probabilities)
            predicted_class = self.svm_model.classes_[np.argmax(probabilities)]
            
            if max_prob < threshold:
                return "Unknown", max_prob
            else:
                return predicted_class, max_prob
        except:
            return "Unknown", 0.0

# ==================== REAL-TIME RECOGNITION ====================
def real_time_recognition():
    """Ch·∫°y real-time recognition v·ªõi g·ª≠i d·ªØ li·ªáu real-time - ƒê√É S·ª¨A L·ªñI"""
    system = CompleteRecognitionSystem()
    
    if not system.initialize_system():
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o h·ªá th·ªëng")
        return
    
    model_loaded = system.load_trained_model()
    if not model_loaded:
        print("‚ö†Ô∏è Ch·∫°y ·ªü ch·∫ø ƒë·ªô ch·ªâ detect c·∫£m x√∫c v√† h√†nh vi")
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
        return
    
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    print("üé• H·ªá th·ªëng ho√†n ch·ªânh ƒë√£ b·∫Øt ƒë·∫ßu!")
    print("üìä T√≠nh nƒÉng: Nh·∫≠n di·ªán khu√¥n m·∫∑t + C·∫£m x√∫c + H√†nh vi + ƒêi·ªÉm danh + Real-time Backend")
    print("üéÆ Nh·∫•n 'q' ƒë·ªÉ tho√°t, 's' ƒë·ªÉ ch·ª•p ·∫£nh, 'v' ƒë·ªÉ xem ƒëi·ªÉm danh")
    
    attendance_status = {}
    frame_count = 0
    
    # KH·ªûI T·∫†O BI·∫æN TR∆Ø·ªöC - S·ª¨A L·ªñI UnboundLocalError
    face_results = []
    behavior_results = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # Gi·∫£m t·∫ßn su·∫•t detection ƒë·ªÉ tƒÉng performance
        if frame_count % 2 == 0:
            face_results = system.detect_faces(frame)
            behavior_results = system.behavior_detector.detect_behavior(frame)
            
            # üî• G·ª¨I D·ªÆ LI·ªÜU REAL-TIME CHO T·∫§T C·∫¢ H·ªåC SINH
            student_data_list = []
            
            for i, face_data in enumerate(face_results):
                bbox = face_data['bbox']
                x, y, w, h = bbox
                emotion = face_data['emotion']
                emotion_conf = face_data['emotion_confidence']
                
                if model_loaded:
                    name, confidence = system.recognize_face(face_data)
                else:
                    name, confidence = "Unknown", 0.0
                
                # T√¨m h√†nh vi t∆∞∆°ng ·ª©ng
                behavior = "normal"
                for behav in behavior_results:
                    if behav['bbox'] is not None:
                        try:
                            bx1, by1, bx2, by2 = behav['bbox'].astype(int)
                            if (x < bx2 and x + w > bx1 and y < by2 and y + h > by1):
                                behavior = behav['behavior']
                                break
                        except:
                            continue
                
                # T·∫°o student data ƒë·ªÉ g·ª≠i real-time
                student_data = {
                    'id': i + 1,
                    'name': name,
                    'status': 'present' if name != "Unknown" else 'unknown',
                    'emotion': emotion,
                    'engagement': confidence,
                    'behavior': behavior,
                    'bbox': {
                        'x': int(x), 'y': int(y), 
                        'width': int(w), 'height': int(h)
                    },
                    'confidence': confidence,
                    'timestamp': datetime.now().isoformat()
                }
                
                student_data_list.append(student_data)
                
                # ƒêi·ªÉm danh n·∫øu nh·∫≠n di·ªán ƒë∆∞·ª£c
                if name != "Unknown" and confidence > 0.6:
                    if name not in attendance_status:
                        bbox_dict = {"x1": x, "y1": y, "x2": x+w, "y2": y+h}
                        system.attendance_system.mark_attendance(
                            name, emotion, behavior, confidence, bbox_dict
                        )
                        attendance_status[name] = True
            
            # G·ª¨I REAL-TIME DATA
            if student_data_list and system.backend_sender.is_connected:
                system.backend_sender.send_realtime_data(student_data_list)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£ - S·ª¨A: LU√îN s·ª≠ d·ª•ng bi·∫øn ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o
        for i, face_data in enumerate(face_results):
            bbox = face_data['bbox']
            x, y, w, h = bbox
            emotion = face_data['emotion']
            emotion_conf = face_data['emotion_confidence']
            
            if model_loaded:
                name, confidence = system.recognize_face(face_data)
                color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)
            else:
                name, confidence = "Unknown", 0.0
                color = (255, 255, 0)
            
            # V·∫Ω bounding box
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            
            # T√¨m h√†nh vi
            behavior_text = "normal"
            for behav in behavior_results:
                if behav['bbox'] is not None:
                    try:
                        bx1, by1, bx2, by2 = behav['bbox'].astype(int)
                        if (x < bx2 and x + w > bx1 and y < by2 and y + h > by1):
                            behavior_text = behav['behavior']
                            break
                    except:
                        continue
            
            # Hi·ªÉn th·ªã th√¥ng tin
            behavior_display = f"{behavior_text}"
            cv2.putText(frame, behavior_display, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            emotion_text = f"{emotion} ({emotion_conf:.1f})"
            cv2.putText(frame, emotion_text, (x, y + h + 25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        # V·∫Ω pose keypoints
        for behavior in behavior_results:
            if behavior['keypoints'] is not None:
                for kpt in behavior['keypoints']:
                    x, y, conf = kpt
                    if conf > 0.3:
                        cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)
        
        # Hi·ªÉn th·ªã tr·∫°ng th√°i real-time
        backend_status = "üü¢ REAL-TIME" if system.backend_sender.is_connected else "üî¥ OFFLINE"
        info_text = f"Faces: {len(face_results)} | Backend: {backend_status}"
        cv2.putText(frame, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.imshow('Real-time Face Recognition + Backend', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            filename = f"capture_{int(time.time())}.jpg"
            cv2.imwrite(filename, frame)
            print(f"‚úÖ ƒê√£ l∆∞u ·∫£nh: {filename}")
        elif key == ord('v'):
            system.attendance_system.view_attendance()
    
    cap.release()
    cv2.destroyAllWindows()
    print("üëã ƒê√£ tho√°t!")

# ==================== C√ÅC H√ÄM PH·ª§ TR·ª¢ ====================
def create_folder_structure():
    """T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c"""
    folders = [
        "database",
        "database/person1",
        "database/person2", 
        "database/person3",
        "test_images"
    ]
    
    for folder in folders:
        os.makedirs(folder, exist_ok=True)
        print(f"‚úÖ ƒê√£ t·∫°o: {folder}/")
    
    print("\nüìÅ C·∫•u tr√∫c th∆∞ m·ª•c ƒë√£ ƒë∆∞·ª£c t·∫°o!")

def train_model():
    """Train model t·ª´ database"""
    system = CompleteRecognitionSystem()
    
    if not system.initialize_system():
        return
    
    if not os.path.exists("database"):
        os.makedirs("database")
        print("üìÅ ƒê√£ t·∫°o th∆∞ m·ª•c 'database'")
        return
    
    success = system.train_face_recognition()
    if success:
        print("üéâ Train model th√†nh c√¥ng!")
    else:
        print("‚ùå Train model th·∫•t b·∫°i!")

def view_attendance():
    """Xem l·ªãch s·ª≠ ƒëi·ªÉm danh"""
    attendance_system = AttendanceSystem()
    attendance_system.view_attendance()

def test_backend_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi backend"""
    sender = BackendDataSender()
    if sender.is_connected:
        print("‚úÖ K·∫øt n·ªëi backend: TH√ÄNH C√îNG")
    else:
        print("‚ùå K·∫øt n·ªëi backend: TH·∫§T B·∫†I")

# ==================== MAIN MENU ====================
def main_menu():
    """Hi·ªÉn th·ªã menu ch√≠nh"""
    while True:
        print("\n" + "="*70)
        print("üé≠ COMPLETE RECOGNITION SYSTEM - FACE + EMOTION + BEHAVIOR + ATTENDANCE + BACKEND")
        print("="*70)
        print("1. üìÅ T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c")
        print("2. üéØ Train face recognition model")
        print("3. üé• Real-time (Face + Emotion + Behavior + Attendance + Backend)")
        print("4. üìä Xem l·ªãch s·ª≠ ƒëi·ªÉm danh")
        print("5. üîó Ki·ªÉm tra k·∫øt n·ªëi backend")
        print("6. üö™ Tho√°t")
        print("="*70)
        
        choice = input("üëâ Ch·ªçn ch·ª©c nƒÉng (1-6): ").strip()
        
        if choice == "1":
            create_folder_structure()
        elif choice == "2":
            train_model()
        elif choice == "3":
            real_time_recognition()
        elif choice == "4":
            view_attendance()
        elif choice == "5":
            test_backend_connection()
        elif choice == "6":
            print("üëã T·∫°m bi·ªát!")
            break
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
        
        input("\nüëâ Nh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")

# ==================== MAIN ====================
if __name__ == "__main__":
    print("üîß ƒêang ki·ªÉm tra h·ªá th·ªëng...")
    install_dependencies()
    
    print("\nüéØ Kh·ªüi ƒë·ªông H·ªá th·ªëng Nh·∫≠n di·ªán Ho√†n ch·ªânh...")
    print("üìä T√≠nh nƒÉng: Nh·∫≠n di·ªán khu√¥n m·∫∑t + C·∫£m x√∫c + H√†nh vi + ƒêi·ªÉm danh + Real-time Backend")
    
    main_menu()