#!/usr/bin/env python3
"""
FACE RECOGNITION SYSTEM - INSIGHTFACE + DEEPFACE + YOLOv11-POSE + ATTENDANCE + REAL-TIME BACKEND
GPU/CPU DUAL MODE - AUTO FALLBACK TO CPU
"""

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.preprocessing import Normalizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pickle
import time
import subprocess
import sys
from datetime import datetime
import requests
import json

# ==================== GPU CONFIGURATION ====================
def setup_gpu():
    """C·∫•u h√¨nh v√† ki·ªÉm tra GPU chi ti·∫øt"""
    print("üîç Ki·ªÉm tra h·ªá th·ªëng GPU...")
    
    # Ki·ªÉm tra PyTorch CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            device_name = torch.cuda.get_device_name(current_device)
            gpu_memory = torch.cuda.get_device_properties(current_device).total_memory / 1024**3
            
            print(f"‚úÖ PyTorch GPU ƒë∆∞·ª£c h·ªó tr·ª£: {device_name}")
            print(f"üéØ S·ªë GPU: {gpu_count}")
            print(f"üíæ B·ªô nh·ªõ GPU: {gpu_memory:.1f} GB")
            
            # Thi·∫øt l·∫≠p GPU m·∫∑c ƒë·ªãnh
            torch.cuda.set_device(current_device)
            return True, 'cuda'
        else:
            print("‚ùå PyTorch kh√¥ng t√¨m th·∫•y GPU")
    except Exception as e:
        print(f"‚ùå L·ªói ki·ªÉm tra PyTorch GPU: {e}")
    
    # Ki·ªÉm tra CUDA qua nvcc
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ NVIDIA CUDA Compiler ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            # Parse version t·ª´ output
            for line in result.stdout.split('\n'):
                if 'release' in line:
                    print(f"üìã CUDA Version: {line}")
        else:
            print("‚ùå NVIDIA CUDA Compiler kh√¥ng kh·∫£ d·ª•ng")
    except:
        print("‚ùå Kh√¥ng th·ªÉ ch·∫°y nvcc - CUDA c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    
    # Ki·ªÉm tra DirectX (cho GPU AMD/Intel)
    try:
        import ctypes
        dxgi = ctypes.windll.dxgi
        print("‚úÖ DirectX GPU kh·∫£ d·ª•ng")
    except:
        print("‚ùå Kh√¥ng th·ªÉ ki·ªÉm tra DirectX")
    
    print("üîß S·ª≠ d·ª•ng CPU mode - H·ªá th·ªëng v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng")
    return False, 'cpu'

def install_dependencies():
    """C√†i ƒë·∫∑t dependencies v·ªõi fallback an to√†n"""
    packages = [
        "torch",
        "torchvision", 
        "opencv-python", 
        "matplotlib",
        "scikit-learn",
        "pillow",
        "numpy",
        "insightface",
        "deepface",
        "pandas",
        "ultralytics",
        "requests"
    ]
    
    # Ki·ªÉm tra xem c√≥ n√™n d√πng onnxruntime-gpu hay kh√¥ng
    gpu_available, _ = setup_gpu()
    if gpu_available:
        packages.append("onnxruntime-gpu")
        print("üéØ S·∫Ω c√†i ƒë·∫∑t onnxruntime-gpu cho GPU")
    else:
        packages.append("onnxruntime")
        print("üéØ S·∫Ω c√†i ƒë·∫∑t onnxruntime th∆∞·ªùng cho CPU")
    
    print("üîß Ki·ªÉm tra v√† c√†i ƒë·∫∑t dependencies...")
    
    for package in packages:
        try:
            if package == "torch":
                import torch
                print(f"‚úÖ torch {torch.__version__} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            elif package == "torchvision":
                import torchvision
                print(f"‚úÖ torchvision {torchvision.__version__} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            elif package == "insightface":
                import insightface
                print("‚úÖ insightface ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            elif package == "deepface":
                import deepface
                print("‚úÖ deepface ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            elif package == "ultralytics":
                import ultralytics
                print(f"‚úÖ ultralytics {ultralytics.__version__} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            elif package == "onnxruntime-gpu":
                try:
                    import onnxruntime
                    print("‚úÖ onnxruntime ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
                    continue
                except ImportError:
                    pass
            else:
                __import__(package.replace('-', '_'))
            print(f"‚úÖ {package} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
        except ImportError:
            print(f"üì• ƒêang c√†i ƒë·∫∑t {package}...")
            try:
                # Th·ª≠ c√†i ƒë·∫∑t v·ªõi user option ƒë·ªÉ tr√°nh l·ªói permission
                subprocess.check_call([sys.executable, "-m", "pip", "install", package, "--user"])
                print(f"‚úÖ ƒê√£ c√†i ƒë·∫∑t {package} v·ªõi --user option")
            except subprocess.CalledProcessError:
                try:
                    # Th·ª≠ c√†i ƒë·∫∑t b√¨nh th∆∞·ªùng
                    subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                    print(f"‚úÖ ƒê√£ c√†i ƒë·∫∑t {package}")
                except subprocess.CalledProcessError as e:
                    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ c√†i ƒë·∫∑t {package}: {e}")
                    print("üö® Ti·∫øp t·ª•c v·ªõi package kh√°c...")

def check_system_capabilities():
    """Ki·ªÉm tra kh·∫£ nƒÉng h·ªá th·ªëng chi ti·∫øt"""
    print("\n" + "="*50)
    print("üîç KI·ªÇM TRA H·ªÜ TH·ªêNG CHI TI·∫æT")
    print("="*50)
    
    # Ki·ªÉm tra Python
    print(f"üêç Python Version: {sys.version}")
    
    # Ki·ªÉm tra OpenCV
    try:
        import cv2
        print(f"üì∑ OpenCV Version: {cv2.__version__}")
    except ImportError:
        print("‚ùå OpenCV ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    
    # Ki·ªÉm tra PyTorch
    try:
        import torch
        print(f"üî• PyTorch Version: {torch.__version__}")
        if torch.cuda.is_available():
            print("üéØ PyTorch CUDA: S·∫¥N S√ÄNG")
            print(f"üîß GPU Name: {torch.cuda.get_device_name(0)}")
            print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("üéØ PyTorch CUDA: KH√îNG S·∫¥N S√ÄNG")
    except ImportError:
        print("‚ùå PyTorch ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    
    # Ki·ªÉm tra ONNX Runtime
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        print(f"üìä ONNX Runtime Providers: {providers}")
    except ImportError:
        print("‚ùå ONNX Runtime ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    
    print("="*50)

# ==================== BACKEND DATA SENDER ====================
class BackendDataSender:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.is_connected = False
        self.last_sent_time = 0
        self.send_interval = 1.0
        self.test_connection()
    
    def test_connection(self):
        """Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn backend"""
        try:
            response = requests.get(f"{self.base_url}/api/health", timeout=3)
            if response.status_code == 200:
                self.is_connected = True
                print("‚úÖ ƒê√£ k·∫øt n·ªëi ƒë·∫øn backend th√†nh c√¥ng!")
            else:
                print(f"‚ö†Ô∏è Backend tr·∫£ v·ªÅ m√£ l·ªói: {response.status_code}")
                self.is_connected = False
        except Exception as e:
            print(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn backend: {str(e)}")
            self.is_connected = False
    
    def can_send_realtime(self):
        """Ki·ªÉm tra xem c√≥ th·ªÉ g·ª≠i real-time data kh√¥ng"""
        current_time = time.time()
        if current_time - self.last_sent_time >= self.send_interval:
            self.last_sent_time = current_time
            return True
        return False
    
    def send_realtime_data(self, student_data_list):
        """G·ª≠i d·ªØ li·ªáu real-time cho t·∫•t c·∫£ h·ªçc sinh ƒë∆∞·ª£c ph√°t hi·ªán"""
        if not self.is_connected or not self.can_send_realtime():
            return False
        
        try:
            present_count = len([s for s in student_data_list if s.get('status') == 'present'])
            total_count = len(student_data_list)
            
            emotion_count = {}
            engagement_scores = []
            
            for student in student_data_list:
                emotion = student.get('emotion', 'neutral')
                emotion_count[emotion] = emotion_count.get(emotion, 0) + 1
                engagement_scores.append(student.get('engagement', 0))
            
            avg_engagement = np.mean(engagement_scores) * 100 if engagement_scores else 75.0
            dominant_emotion = max(emotion_count.items(), key=lambda x: x[1])[0] if emotion_count else 'neutral'
            
            data = {
                "type": "live_update",
                "timestamp": datetime.now().isoformat(),
                "students": student_data_list,
                "stats": {
                    "total_students": total_count,
                    "present_count": present_count,
                    "absent_count": max(5 - present_count, 0),
                    "attendance_rate": round((present_count / max(total_count, 1)) * 100, 1),
                    "avg_engagement": round(avg_engagement, 1),
                    "current_emotion": dominant_emotion
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/realtime/update",
                json=data,
                timeout=2
            )
            
            if response.status_code == 200:
                print(f"üì§ Real-time: {len(student_data_list)} students, {avg_engagement:.1f}% engagement")
                return True
            else:
                try:
                    ws_response = requests.post(
                        f"{self.base_url}/api/websocket/broadcast",
                        json=data,
                        timeout=2
                    )
                    return ws_response.status_code == 200
                except:
                    return False
                
        except Exception as e:
            return False

# ==================== BEHAVIOR DETECTION ====================
class BehaviorDetector:
    def __init__(self, device='cpu'):
        self.pose_model = None
        self.device = device
        self.initialize_pose_detector()
    
    def initialize_pose_detector(self):
        """Kh·ªüi t·∫°o YOLOv11 pose detector"""
        try:
            from ultralytics import YOLO
            
            print("üì• ƒêang t·∫£i YOLOv11 pose model...")
            self.pose_model = YOLO('yolo11n-pose.pt')
            
            if self.device == 'cuda':
                try:
                    import torch
                    if torch.cuda.is_available():
                        self.pose_model.to('cuda')
                        print("‚úÖ YOLOv11 Pose detector ƒë√£ s·∫µn s√†ng (GPU)")
                    else:
                        print("‚úÖ YOLOv11 Pose detector ƒë√£ s·∫µn s√†ng (CPU - Fallback)")
                        self.device = 'cpu'
                except:
                    print("‚úÖ YOLOv11 Pose detector ƒë√£ s·∫µn s√†ng (CPU - Fallback)")
                    self.device = 'cpu'
            else:
                print("‚úÖ YOLOv11 Pose detector ƒë√£ s·∫µn s√†ng (CPU)")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o YOLOv11 Pose: {str(e)}")
            return False
    
    def detect_behavior(self, image):
        """Nh·∫≠n di·ªán h√†nh vi t·ª´ pose estimation"""
        try:
            device = '0' if self.device == 'cuda' else 'cpu'
            results = self.pose_model(image, verbose=False, device=device)
            
            behaviors = []
            
            for result in results:
                if hasattr(result, 'keypoints') and result.keypoints is not None and len(result.keypoints) > 0:
                    for person_idx, keypoints in enumerate(result.keypoints.data):
                        kpts = keypoints.cpu().numpy()
                        behavior = self._analyze_pose_behavior(kpts)
                        
                        bbox = None
                        if hasattr(result, 'boxes') and result.boxes is not None and len(result.boxes) > person_idx:
                            bbox = result.boxes[person_idx].xyxy[0].cpu().numpy()
                        
                        behaviors.append({
                            'behavior': behavior,
                            'keypoints': kpts,
                            'bbox': bbox,
                            'person_idx': person_idx
                        })
            
            return behaviors
            
        except Exception as e:
            print(f"‚ùå L·ªói nh·∫≠n di·ªán h√†nh vi: {str(e)}")
            return []
    
    def _analyze_pose_behavior(self, keypoints):
        """Ph√¢n t√≠ch h√†nh vi d·ª±a tr√™n keypoints pose"""
        try:
            # Ch·ªâ s·ªë keypoints theo COCO format
            LEFT_SHOULDER = 5
            RIGHT_SHOULDER = 6
            LEFT_ELBOW = 7
            RIGHT_ELBOW = 8
            LEFT_WRIST = 9
            RIGHT_WRIST = 10
            LEFT_HIP = 11
            RIGHT_HIP = 12
            LEFT_KNEE = 13
            RIGHT_KNEE = 14
            
            def get_point(idx):
                if keypoints[idx][2] > 0.3:
                    return keypoints[idx][:2]
                return None
            
            left_shoulder = get_point(LEFT_SHOULDER)
            right_shoulder = get_point(RIGHT_SHOULDER)
            left_elbow = get_point(LEFT_ELBOW)
            right_elbow = get_point(RIGHT_ELBOW)
            left_wrist = get_point(LEFT_WRIST)
            right_wrist = get_point(RIGHT_WRIST)
            left_hip = get_point(LEFT_HIP)
            right_hip = get_point(RIGHT_HIP)
            left_knee = get_point(LEFT_KNEE)
            right_knee = get_point(RIGHT_KNEE)
            
            behaviors = []
            
            # Ki·ªÉm tra gi∆° tay
            if left_wrist is not None and left_shoulder is not None:
                if left_wrist[1] < left_shoulder[1]:
                    behaviors.append("raising_hand")
            if right_wrist is not None and right_shoulder is not None:
                if right_wrist[1] < right_shoulder[1]:
                    behaviors.append("raising_hand")
            
            # Ki·ªÉm tra ƒë·ª©ng/ng·ªìi
            if (left_hip is not None and left_knee is not None and 
                right_hip is not None and right_knee is not None):
                hip_height = (left_hip[1] + right_hip[1]) / 2
                knee_height = (left_knee[1] + right_knee[1]) / 2
                if abs(hip_height - knee_height) < 50:
                    behaviors.append("standing")
                else:
                    behaviors.append("sitting")
            
            # Ki·ªÉm tra v·ªó tay
            if left_wrist is not None and right_wrist is not None:
                distance = np.sqrt(np.sum((left_wrist - right_wrist) ** 2))
                if distance < 50:
                    behaviors.append("clapping")
            
            if not behaviors:
                behaviors.append("normal")
            
            return ", ".join(behaviors)
            
        except Exception as e:
            print(f"‚ùå L·ªói ph√¢n t√≠ch h√†nh vi: {str(e)}")
            return "unknown"

# ==================== ATTENDANCE SYSTEM ====================
class AttendanceSystem:
    def __init__(self, csv_file="attendance.csv"):
        self.csv_file = csv_file
        self.backend_sender = BackendDataSender()
        self.initialize_attendance_file()
    
    def initialize_attendance_file(self):
        """Kh·ªüi t·∫°o file ƒëi·ªÉm danh"""
        try:
            if not os.path.exists(self.csv_file):
                df = pd.DataFrame(columns=[
                    'Name', 'Date', 'Time', 'Emotion', 'Behavior', 'Confidence'
                ])
                df.to_csv(self.csv_file, index=False)
                print(f"‚úÖ ƒê√£ t·∫°o file ƒëi·ªÉm danh: {self.csv_file}")
            else:
                df = pd.read_csv(self.csv_file)
                print(f"‚úÖ File ƒëi·ªÉm danh ƒë√£ t·ªìn t·∫°i: {len(df)} records")
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o file ƒëi·ªÉm danh: {str(e)}")
    
    def mark_attendance(self, name, emotion, behavior, confidence, bbox=None):
        """ƒêi·ªÉm danh v√†o file CSV v√† g·ª≠i l√™n backend"""
        try:
            now = datetime.now()
            date_str = now.strftime("%Y-%m-%d")
            time_str = now.strftime("%H:%M:%S")
            
            student_id = f"SV{hash(name) % 10000:04d}"
            
            # G·ª≠i d·ªØ li·ªáu l√™n backend
            if self.backend_sender.is_connected:
                self.backend_sender.send_face_detection(
                    student_id=student_id,
                    student_name=name,
                    emotion=emotion,
                    confidence=confidence,
                    bbox=bbox or {"x1": 0, "y1": 0, "x2": 100, "y2": 100}
                )
                
                engagement_score = confidence * 100
                self.backend_sender.send_behavior_data(
                    student_id=student_id,
                    student_name=name,
                    behavior_type="engagement",
                    score=engagement_score,
                    details=json.dumps({"behavior": behavior, "emotion": emotion})
                )
                
                self.backend_sender.mark_attendance(student_id, name, "present")
            
            # L∆∞u v√†o file local
            try:
                df = pd.read_csv(self.csv_file)
            except:
                df = pd.DataFrame(columns=[
                    'Name', 'Date', 'Time', 'Emotion', 'Behavior', 'Confidence'
                ])
            
            # Ki·ªÉm tra ƒëi·ªÉm danh trong v√≤ng 2 ph√∫t
            two_minutes_ago = (datetime.now() - pd.Timedelta(minutes=2)).strftime("%H:%M:%S")
            recent_entries = df[
                (df['Name'] == name) & 
                (df['Date'] == date_str) & 
                (df['Time'] > two_minutes_ago)
            ]
            
            if len(recent_entries) == 0:
                new_entry = {
                    'Name': name,
                    'Date': date_str,
                    'Time': time_str,
                    'Emotion': emotion,
                    'Behavior': behavior,
                    'Confidence': f"{confidence:.4f}"
                }
                
                df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)
                df.to_csv(self.csv_file, index=False)
                print(f"‚úÖ ƒê√£ ƒëi·ªÉm danh: {name} | üòä {emotion} | üéØ {behavior}")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"‚ùå L·ªói ƒëi·ªÉm danh: {str(e)}")
            return False
    
    def view_attendance(self):
        """Xem l·ªãch s·ª≠ ƒëi·ªÉm danh"""
        try:
            if not os.path.exists(self.csv_file):
                print("üì≠ Ch∆∞a c√≥ file ƒëi·ªÉm danh")
                return
                
            df = pd.read_csv(self.csv_file)
            if len(df) > 0:
                print("\nüìä L·ªäCH S·ª¨ ƒêI·ªÇM DANH:")
                print("=" * 80)
                for _, row in df.iterrows():
                    print(f"üë§ {row['Name']} | üìÖ {row['Date']} | üïí {row['Time']} | üòä {row['Emotion']} | üéØ {row['Behavior']}")
                print("=" * 80)
                print(f"üìà T·ªïng s·ªë l∆∞·ª£t ƒëi·ªÉm danh: {len(df)}")
            else:
                print("üì≠ Ch∆∞a c√≥ d·ªØ li·ªáu ƒëi·ªÉm danh")
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file ƒëi·ªÉm danh: {str(e)}")

# ==================== EMOTION DETECTION ====================
class EmotionDetector:
    def __init__(self):
        self.emotion_model = None
    
    def detect_emotion(self, face_image):
        """Nh·∫≠n di·ªán c·∫£m x√∫c t·ª´ khu√¥n m·∫∑t"""
        try:
            from deepface import DeepFace
            
            face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
            
            analysis = DeepFace.analyze(
                face_rgb, 
                actions=['emotion'],
                enforce_detection=False,
                silent=True
            )
            
            if isinstance(analysis, list):
                analysis = analysis[0]
            
            emotion = analysis['dominant_emotion']
            emotion_confidence = analysis['emotion'][emotion]
            
            return emotion, emotion_confidence
            
        except Exception as e:
            print(f"‚ùå L·ªói nh·∫≠n di·ªán c·∫£m x√∫c: {str(e)}")
            return "unknown", 0.0

# ==================== FACE RECOGNITION SYSTEM ====================
class CompleteRecognitionSystem:
    def __init__(self, model_name='buffalo_l', device='cpu'):
        self.model_name = model_name
        self.device = device
        self.face_analyzer = None
        self.l2_normalizer = Normalizer('l2')
        self.emotion_detector = EmotionDetector()
        self.behavior_detector = BehaviorDetector(device=device)
        self.attendance_system = AttendanceSystem()
        self.backend_sender = BackendDataSender()
        
    def initialize_system(self):
        """Kh·ªüi t·∫°o to√†n b·ªô h·ªá th·ªëng"""
        print("üöÄ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng ho√†n ch·ªânh...")
        
        # Kh·ªüi t·∫°o InsightFace
        try:
            import insightface
            from insightface.app import FaceAnalysis
            
            print("üì• ƒêang t·∫£i InsightFace model...")
            self.face_analyzer = FaceAnalysis(name=self.model_name)
            self.face_analyzer.prepare(ctx_id=0, det_size=(640, 640))
            print("‚úÖ InsightFace ƒë√£ kh·ªüi t·∫°o th√†nh c√¥ng!")
            
        except Exception as e:
            print(f"‚ùå L·ªói kh·ªüi t·∫°o InsightFace: {str(e)}")
            return False
        
        # Kh·ªüi t·∫°o Behavior Detector
        if not self.behavior_detector.initialize_pose_detector():
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ kh·ªüi t·∫°o Behavior Detector")
        
        print("‚úÖ H·ªá th·ªëng ho√†n ch·ªânh ƒë√£ s·∫µn s√†ng!")
        return True

    def detect_faces(self, image):
        """Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi InsightFace"""
        try:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            faces = self.face_analyzer.get(image_rgb)
            
            face_results = []
            for face in faces:
                bbox = face.bbox.astype(int)
                x1, y1, x2, y2 = bbox
                w = x2 - x1
                h = y2 - y1
                
                face_roi = image[y1:y2, x1:x2]
                if face_roi.size == 0:
                    continue
                
                embedding = face.normed_embedding
                
                # Nh·∫≠n di·ªán c·∫£m x√∫c
                emotion, emotion_conf = self.emotion_detector.detect_emotion(face_roi)
                
                face_results.append({
                    'face_image': face_roi,
                    'bbox': (x1, y1, w, h),
                    'embedding': embedding,
                    'det_score': face.det_score,
                    'landmarks': face.kps if hasattr(face, 'kps') else None,
                    'emotion': emotion,
                    'emotion_confidence': emotion_conf
                })
            
            return face_results
            
        except Exception as e:
            print(f"‚ùå L·ªói detect faces: {str(e)}")
            return []

    def extract_features(self, face_data):
        """Tr√≠ch xu·∫•t features t·ª´ khu√¥n m·∫∑t"""
        try:
            embedding = face_data['embedding']
            embedding = embedding.reshape(1, -1)
            features_normalized = self.l2_normalizer.transform(embedding)
            return features_normalized[0]
        except Exception as e:
            print(f"‚ùå L·ªói extract features: {str(e)}")
            return None

    def train_face_recognition(self, database_path="database"):
        """Train h·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t"""
        if not os.path.exists(database_path):
            print(f"‚ùå Th∆∞ m·ª•c database kh√¥ng t·ªìn t·∫°i: {database_path}")
            return False
        
        database = {}
        features_list = []
        labels_list = []
        
        print("üìÅ ƒêang x·ª≠ l√Ω database...")
        
        persons = [p for p in os.listdir(database_path) if os.path.isdir(os.path.join(database_path, p))]
        if len(persons) < 1:
            print("‚ùå Kh√¥ng c√≥ ng∆∞·ªùi n√†o trong database!")
            return False
        
        for person_name in persons:
            person_path = os.path.join(database_path, person_name)
            print(f"üë§ ƒêang x·ª≠ l√Ω: {person_name}")
            person_features = []
            
            image_files = [f for f in os.listdir(person_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            for image_file in image_files:
                image_path = os.path.join(person_path, image_file)
                image = cv2.imread(image_path)
                if image is None:
                    continue
                
                face_results = self.detect_faces(image)
                for face_data in face_results:
                    features = self.extract_features(face_data)
                    if features is not None:
                        person_features.append(features)
                        features_list.append(features)
                        labels_list.append(person_name)
            
            if person_features:
                database[person_name] = person_features
                print(f"  ‚ûï {person_name}: {len(person_features)} khu√¥n m·∫∑t")
        
        if len(features_list) == 0:
            print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ train!")
            return False
        
        print(f"\nüìä Th·ªëng k√™ database:")
        print(f"üë• S·ªë ng∆∞·ªùi: {len(database)}")
        print(f"üñºÔ∏è T·ªïng khu√¥n m·∫∑t: {len(features_list)}")
        
        # Train SVM model
        print("\nüéØ ƒêang train SVM model...")
        self.svm_model = SVC(kernel='linear', probability=True, random_state=42)
        self.svm_model.fit(features_list, labels_list)
        
        accuracy = accuracy_score(labels_list, self.svm_model.predict(features_list))
        print(f"‚úÖ Training ho√†n t·∫•t! Accuracy: {accuracy:.4f}")
        
        # L∆∞u model
        with open("face_recognition_model.pkl", 'wb') as f:
            pickle.dump(self.svm_model, f)
        
        with open("face_database.pkl", 'wb') as f:
            pickle.dump({
                'database': database,
                'features': features_list,
                'labels': labels_list
            }, f)
        
        print("üíæ ƒê√£ l∆∞u model v√† database")
        return True

    def load_trained_model(self):
        """Load model ƒë√£ train"""
        try:
            with open("face_recognition_model.pkl", 'rb') as f:
                self.svm_model = pickle.load(f)
            
            with open("face_database.pkl", 'rb') as f:
                db_info = pickle.load(f)
            
            print(f"‚úÖ ƒê√£ load trained model - {len(self.svm_model.classes_)} classes")
            return True
            
        except FileNotFoundError:
            print("‚ùå Kh√¥ng t√¨m th·∫•y file model. Vui l√≤ng train model tr∆∞·ªõc.")
            return False

    def recognize_face(self, face_data, threshold=0.6):
        """Nh·∫≠n di·ªán khu√¥n m·∫∑t"""
        if not hasattr(self, 'svm_model') or self.svm_model is None:
            return "Unknown", 0.0
        
        features = self.extract_features(face_data)
        if features is None:
            return "Unknown", 0.0
        
        try:
            probabilities = self.svm_model.predict_proba([features])[0]
            max_prob = np.max(probabilities)
            predicted_class = self.svm_model.classes_[np.argmax(probabilities)]
            
            if max_prob < threshold:
                return "Unknown", max_prob
            else:
                return predicted_class, max_prob
        except:
            return "Unknown", 0.0

# ==================== REAL-TIME RECOGNITION ====================
def real_time_recognition():
    """Ch·∫°y real-time recognition v·ªõi optimization"""
    # Ki·ªÉm tra v√† thi·∫øt l·∫≠p GPU
    gpu_available, device = setup_gpu()
    
    system = CompleteRecognitionSystem(device=device)
    
    if not system.initialize_system():
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o h·ªá th·ªëng")
        return
    
    model_loaded = system.load_trained_model()
    if not model_loaded:
        print("‚ö†Ô∏è Ch·∫°y ·ªü ch·∫ø ƒë·ªô ch·ªâ detect c·∫£m x√∫c v√† h√†nh vi")
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü webcam!")
        return
    
    # C√†i ƒë·∫∑t camera ph√π h·ª£p v·ªõi CPU
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 15)
    
    print("üé• H·ªá th·ªëng ho√†n ch·ªânh ƒë√£ b·∫Øt ƒë·∫ßu!")
    print(f"‚ö° Ch·∫ø ƒë·ªô: {'GPU ACCELERATED' if gpu_available else 'CPU OPTIMIZED'}")
    print("üìä T√≠nh nƒÉng: Nh·∫≠n di·ªán khu√¥n m·∫∑t + C·∫£m x√∫c + H√†nh vi + ƒêi·ªÉm danh + Real-time Backend")
    print("üéÆ Nh·∫•n 'q' ƒë·ªÉ tho√°t, 's' ƒë·ªÉ ch·ª•p ·∫£nh, 'v' ƒë·ªÉ xem ƒëi·ªÉm danh")
    
    attendance_status = {}
    frame_count = 0
    
    # KH·ªûI T·∫†O BI·∫æN TR∆Ø·ªöC
    face_results = []
    behavior_results = []
    
    # Bi·∫øn ƒë·ªÉ ƒëo FPS
    fps_counter = 0
    fps_time = time.time()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        fps_counter += 1
        
        # T√≠nh FPS
        current_time = time.time()
        if current_time - fps_time >= 1.0:
            fps = fps_counter / (current_time - fps_time)
            fps_counter = 0
            fps_time = current_time
            fps_text = f"FPS: {fps:.1f}"
        else:
            fps_text = "FPS: calculating..."
        
        # Gi·∫£m t·∫ßn su·∫•t detection ƒë·ªÉ tƒÉng performance tr√™n CPU
        detection_interval = 3  # CPU ch·∫≠m h∆°n n√™n detection √≠t th∆∞·ªùng xuy√™n h∆°n
        
        if frame_count % detection_interval == 0:
            face_results = system.detect_faces(frame)
            behavior_results = system.behavior_detector.detect_behavior(frame)
            
            # G·ª¨I D·ªÆ LI·ªÜU REAL-TIME
            student_data_list = []
            
            for i, face_data in enumerate(face_results):
                bbox = face_data['bbox']
                x, y, w, h = bbox
                emotion = face_data['emotion']
                emotion_conf = face_data['emotion_confidence']
                
                if model_loaded:
                    name, confidence = system.recognize_face(face_data)
                else:
                    name, confidence = "Unknown", 0.0
                
                # T√¨m h√†nh vi t∆∞∆°ng ·ª©ng
                behavior = "normal"
                for behav in behavior_results:
                    if behav['bbox'] is not None:
                        try:
                            bx1, by1, bx2, by2 = behav['bbox'].astype(int)
                            if (x < bx2 and x + w > bx1 and y < by2 and y + h > by1):
                                behavior = behav['behavior']
                                break
                        except:
                            continue
                
                # T·∫°o student data ƒë·ªÉ g·ª≠i real-time
                student_data = {
                    'id': i + 1,
                    'name': name,
                    'status': 'present' if name != "Unknown" else 'unknown',
                    'emotion': emotion,
                    'engagement': confidence,
                    'behavior': behavior,
                    'bbox': {
                        'x': int(x), 'y': int(y), 
                        'width': int(w), 'height': int(h)
                    },
                    'confidence': confidence,
                    'timestamp': datetime.now().isoformat()
                }
                
                student_data_list.append(student_data)
                
                # ƒêi·ªÉm danh n·∫øu nh·∫≠n di·ªán ƒë∆∞·ª£c
                if name != "Unknown" and confidence > 0.6:
                    if name not in attendance_status:
                        bbox_dict = {"x1": x, "y1": y, "x2": x+w, "y2": y+h}
                        system.attendance_system.mark_attendance(
                            name, emotion, behavior, confidence, bbox_dict
                        )
                        attendance_status[name] = True
            
            # G·ª¨I REAL-TIME DATA
            if student_data_list and system.backend_sender.is_connected:
                system.backend_sender.send_realtime_data(student_data_list)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        for i, face_data in enumerate(face_results):
            bbox = face_data['bbox']
            x, y, w, h = bbox
            emotion = face_data['emotion']
            emotion_conf = face_data['emotion_confidence']
            
            if model_loaded:
                name, confidence = system.recognize_face(face_data)
                color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)
            else:
                name, confidence = "Unknown", 0.0
                color = (255, 255, 0)
            
            # V·∫Ω bounding box
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            
            # T√¨m h√†nh vi
            behavior_text = "normal"
            for behav in behavior_results:
                if behav['bbox'] is not None:
                    try:
                        bx1, by1, bx2, by2 = behav['bbox'].astype(int)
                        if (x < bx2 and x + w > bx1 and y < by2 and y + h > by1):
                            behavior_text = behav['behavior']
                            break
                    except:
                        continue
            
            # Hi·ªÉn th·ªã th√¥ng tin
            info_text = f"{name} ({confidence:.2f})"
            cv2.putText(frame, info_text, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            behavior_display = f"{behavior_text}"
            cv2.putText(frame, behavior_display, (x, y - 35), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            emotion_text = f"{emotion} ({emotion_conf:.1f})"
            cv2.putText(frame, emotion_text, (x, y + h + 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        # Hi·ªÉn th·ªã tr·∫°ng th√°i
        backend_status = "üü¢ REAL-TIME" if system.backend_sender.is_connected else "üî¥ OFFLINE"
        device_status = "‚ö° GPU" if gpu_available else "üíª CPU"
        info_text = f"Faces: {len(face_results)} | Backend: {backend_status} | Device: {device_status} | {fps_text}"
        cv2.putText(frame, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        cv2.imshow('Real-time Face Recognition + Backend', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            filename = f"capture_{int(time.time())}.jpg"
            cv2.imwrite(filename, frame)
            print(f"‚úÖ ƒê√£ l∆∞u ·∫£nh: {filename}")
        elif key == ord('v'):
            system.attendance_system.view_attendance()
    
    cap.release()
    cv2.destroyAllWindows()
    print("üëã ƒê√£ tho√°t!")

# ==================== C√ÅC H√ÄM PH·ª§ TR·ª¢ ====================
def create_folder_structure():
    """T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c"""
    folders = [
        "database",
        "database/person1",
        "database/person2", 
        "database/person3",
        "test_images"
    ]
    
    for folder in folders:
        os.makedirs(folder, exist_ok=True)
        print(f"‚úÖ ƒê√£ t·∫°o: {folder}/")
    
    print("\nüìÅ C·∫•u tr√∫c th∆∞ m·ª•c ƒë√£ ƒë∆∞·ª£c t·∫°o!")

def train_model():
    """Train model t·ª´ database"""
    gpu_available, device = setup_gpu()
    system = CompleteRecognitionSystem(device=device)
    
    if not system.initialize_system():
        return
    
    if not os.path.exists("database"):
        os.makedirs("database")
        print("üìÅ ƒê√£ t·∫°o th∆∞ m·ª•c 'database'")
        print("üí° H√£y th√™m ·∫£nh c·ªßa b·∫°n v√†o th∆∞ m·ª•c database/person1, database/person2, etc.")
        return
    
    success = system.train_face_recognition()
    if success:
        print("üéâ Train model th√†nh c√¥ng!")
    else:
        print("‚ùå Train model th·∫•t b·∫°i!")

def view_attendance():
    """Xem l·ªãch s·ª≠ ƒëi·ªÉm danh"""
    attendance_system = AttendanceSystem()
    attendance_system.view_attendance()

def test_backend_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi backend"""
    sender = BackendDataSender()
    if sender.is_connected:
        print("‚úÖ K·∫øt n·ªëi backend: TH√ÄNH C√îNG")
    else:
        print("‚ùå K·∫øt n·ªëi backend: TH·∫§T B·∫†I")

def troubleshoot_gpu():
    """Kh·∫Øc ph·ª•c s·ª± c·ªë GPU"""
    print("\n" + "="*60)
    print("üîß KH·∫ÆC PH·ª§C S·ª∞ C·ªê GPU")
    print("="*60)
    
    print("1. üìã Ki·ªÉm tra card ƒë·ªì h·ªça:")
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ NVIDIA GPU ƒë∆∞·ª£c ph√°t hi·ªán")
            print(result.stdout.split('\n')[0])  # Hi·ªÉn th·ªã d√≤ng ƒë·∫ßu ti√™n
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y NVIDIA GPU ho·∫∑c driver")
    except:
        print("‚ùå Kh√¥ng th·ªÉ ch·∫°y nvidia-smi")
    
    print("\n2. üîÑ C√†i ƒë·∫∑t PyTorch v·ªõi CUDA support:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n3. üíª Ki·ªÉm tra h·ªá th·ªëng:")
    print("   - Card ƒë·ªì h·ªça NVIDIA v·ªõi CUDA support")
    print("   - Driver NVIDIA m·ªõi nh·∫•t")
    print("   - CUDA Toolkit ƒë∆∞·ª£c c√†i ƒë·∫∑t")
    print("   - PyTorch v·ªõi CUDA support")
    
    print("\n4. ‚ö° T·ªëi ∆∞u h√≥a CPU:")
    print("   - Gi·∫£m ƒë·ªô ph√¢n gi·∫£i camera")
    print("   - Gi·∫£m t·∫ßn su·∫•t detection")
    print("   - S·ª≠ d·ª•ng model nh·∫π h∆°n")
    
    print("="*60)

# ==================== MAIN MENU ====================
def main_menu():
    """Hi·ªÉn th·ªã menu ch√≠nh"""
    # Ki·ªÉm tra h·ªá th·ªëng chi ti·∫øt
    check_system_capabilities()
    
    while True:
        print("\n" + "="*70)
        print("üé≠ COMPLETE RECOGNITION SYSTEM - FACE + EMOTION + BEHAVIOR + ATTENDANCE")
        print("="*70)
        print("1. üìÅ T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c")
        print("2. üéØ Train face recognition model")
        print("3. üé• Real-time (Face + Emotion + Behavior + Attendance + Backend)")
        print("4. üìä Xem l·ªãch s·ª≠ ƒëi·ªÉm danh")
        print("5. üîó Ki·ªÉm tra k·∫øt n·ªëi backend")
        print("6. üîß Kh·∫Øc ph·ª•c s·ª± c·ªë GPU")
        print("7. üö™ Tho√°t")
        print("="*70)
        
        choice = input("üëâ Ch·ªçn ch·ª©c nƒÉng (1-7): ").strip()
        
        if choice == "1":
            create_folder_structure()
        elif choice == "2":
            train_model()
        elif choice == "3":
            real_time_recognition()
        elif choice == "4":
            view_attendance()
        elif choice == "5":
            test_backend_connection()
        elif choice == "6":
            troubleshoot_gpu()
        elif choice == "7":
            print("üëã T·∫°m bi·ªát!")
            break
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
        
        input("\nüëâ Nh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")

# ==================== MAIN ====================
if __name__ == "__main__":
    print("üîß ƒêang ki·ªÉm tra h·ªá th·ªëng...")
    install_dependencies()
    
    print("\nüéØ Kh·ªüi ƒë·ªông H·ªá th·ªëng Nh·∫≠n di·ªán Ho√†n ch·ªânh...")
    print("üìä T√≠nh nƒÉng: Nh·∫≠n di·ªán khu√¥n m·∫∑t + C·∫£m x√∫c + H√†nh vi + ƒêi·ªÉm danh + Real-time Backend")
    
    main_menu()
